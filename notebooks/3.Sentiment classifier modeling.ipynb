{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tqdm\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>text length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.419307e+18</td>\n",
       "      <td>face bound border two The covid said hidden</td>\n",
       "      <td>2021-07-25 17:43:34 EAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-0.1666</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.419307e+18</td>\n",
       "      <td>I seeing looking like second global going</td>\n",
       "      <td>2021-07-25 17:43:34 EAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.419307e+18</td>\n",
       "      <td>sentence people intensive care</td>\n",
       "      <td>2021-07-25 17:43:33 EAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.419307e+18</td>\n",
       "      <td>contagious delta variant surging across nation...</td>\n",
       "      <td>2021-07-25 17:43:31 EAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.419307e+18</td>\n",
       "      <td>sentence people intensive care</td>\n",
       "      <td>2021-07-25 17:43:28 EAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id                                               text  \\\n",
       "0  1.419307e+18        face bound border two The covid said hidden   \n",
       "1  1.419307e+18          I seeing looking like second global going   \n",
       "2  1.419307e+18                     sentence people intensive care   \n",
       "3  1.419307e+18  contagious delta variant surging across nation...   \n",
       "4  1.419307e+18                     sentence people intensive care   \n",
       "\n",
       "                created_at  likes  text length  polarity sentiment  target  \\\n",
       "0  2021-07-25 17:43:34 EAT    0.0         43.0   -0.1666  negative      -1   \n",
       "1  2021-07-25 17:43:34 EAT    0.0         41.0    0.0000   neutral       0   \n",
       "2  2021-07-25 17:43:33 EAT    0.0         30.0    0.0000   neutral       0   \n",
       "3  2021-07-25 17:43:31 EAT    0.0         98.0    0.0000   neutral       0   \n",
       "4  2021-07-25 17:43:28 EAT    0.0         30.0    0.0000   neutral       0   \n",
       "\n",
       "   UserName  ScreenName Location TweetAt Sentiment   ID  \n",
       "0       NaN         NaN      NaN     NaN       NaN  NaN  \n",
       "1       NaN         NaN      NaN     NaN       NaN  NaN  \n",
       "2       NaN         NaN      NaN     NaN       NaN  NaN  \n",
       "3       NaN         NaN      NaN     NaN       NaN  NaN  \n",
       "4       NaN         NaN      NaN     NaN       NaN  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "##\n",
    "tweets = pd.read_csv(\"../csv files/ALL_DATA_V2.csv\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the missing data points row-wise\n",
    "##\n",
    "tweets.dropna(axis=0, subset=['text'], inplace=True)\n",
    "tweets.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BOW (bag of words)\n",
    "##\n",
    "cv = CountVectorizer(analyzer='word', stop_words=stop)\n",
    "\n",
    "cv.fit(tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20417\n"
     ]
    }
   ],
   "source": [
    "# Preview vocabulary and the number of vocab words\n",
    "##\n",
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face',\n",
       " 'bound',\n",
       " 'border',\n",
       " 'two',\n",
       " 'covid',\n",
       " 'said',\n",
       " 'hidden',\n",
       " 'seeing',\n",
       " 'looking',\n",
       " 'like']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2061)\t1\n",
      "  (0, 2101)\t1\n",
      "  (0, 3986)\t1\n",
      "  (0, 6362)\t1\n",
      "  (0, 8204)\t1\n",
      "  (0, 15444)\t1\n",
      "  (0, 18732)\t1\n"
     ]
    }
   ],
   "source": [
    "# Example transforming a single text\n",
    "##\n",
    "print(cv.transform([tweets['text'][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gorgeous'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example getting the feature name by index\n",
    "##\n",
    "cv.get_feature_names()[7591]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the whole BOW to a sparse matrix\n",
    "##\n",
    "bow_text = cv.transform(tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1413194"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-zero occurrences\n",
    "##\n",
    "bow_text.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf weighting\n",
    "##\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_transformer.fit(bow_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 18732)\t0.3540890140004211\n",
      "  (0, 15444)\t0.33005940555536084\n",
      "  (0, 8204)\t0.43847752566461773\n",
      "  (0, 6362)\t0.3557708794716271\n",
      "  (0, 3986)\t0.27601539418774257\n",
      "  (0, 2101)\t0.4403711131831057\n",
      "  (0, 2061)\t0.4203987210029645\n"
     ]
    }
   ],
   "source": [
    "# Example transforming a single bow\n",
    "##\n",
    "print(tfidf_transformer.transform(cv.transform([tweets['text'][0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.902696566057591"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example getting idf weight of a word\n",
    "##\n",
    "tfidf_transformer.idf_[cv.vocabulary_['good']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the whole sparse matrix\n",
    "##\n",
    "tfidf_text = tfidf_transformer.transform(bow_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding 'text length' and 'word count' as features to the model  \n",
    "We'll stack the features to the sparse matrix horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Transforming the two columns into sparse matrices\\n##\\ntxt_length = coo_matrix(tweets[\\'text length\\']).reshape(1182,1)\\nwrd_cnt = coo_matrix(tweets[\\'word count\\']).reshape(1182,1)\\n\\nfeatures = hstack([tfidf_text, txt_length, wrd_cnt])\\n\\n# Preview difference in shapes\\nprint(\"Shape of text column sparse matrix: \", tfidf_text.shape)\\nprint(\"Shape of concatenated features sparse matrix: \", features.shape)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Transforming the two columns into sparse matrices\n",
    "##\n",
    "txt_length = coo_matrix(tweets['text length']).reshape(1182,1)\n",
    "wrd_cnt = coo_matrix(tweets['word count']).reshape(1182,1)\n",
    "\n",
    "features = hstack([tfidf_text, txt_length, wrd_cnt])\n",
    "\n",
    "# Preview difference in shapes\n",
    "print(\"Shape of text column sparse matrix: \", tfidf_text.shape)\n",
    "print(\"Shape of concatenated features sparse matrix: \", features.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tfidf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different classification models:  \n",
    "- Logistic Regression\n",
    "- Linear SVC (svm)\n",
    "- SGD Classifier\n",
    "- Random Forest Classifier\n",
    "- Xgboost Classifier\n",
    "- LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test splits\n",
    "##\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, tweets['target'],stratify=tweets.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "##\n",
    "lr = LogisticRegression(C=2.0, class_weight=None, dual=False, max_iter=100)\n",
    "\n",
    "svc = LinearSVC(C=2.0, class_weight=None, dual=False, max_iter=100)\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=False, class_weight=None, \n",
    "                             criterion='entropy', min_samples_split=6, n_estimators=160, warm_start=False)\n",
    "\n",
    "xgb = XGBClassifier(objective='multi:softmax', num_class=3)\n",
    "\n",
    "lgbm = LGBMClassifier(objective='multiclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting [LogisticRegression]\n",
      "\n",
      "Fitting [LinearSVC]\n",
      "\n",
      "Fitting [SGDClassifier]\n",
      "\n",
      "Fitting [RandomForestClassifier]\n",
      "\n",
      "Fitting [XGBClassifier]\n",
      "[23:51:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "Fitting [LGBMClassifier]\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "models = [lr, svc, enumeratec, xgb, lgbm]\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\nFitting [{model.__class__.__name__}]\")\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting for [LogisticRegression]\n",
      "\n",
      "Predicting for [LinearSVC]\n",
      "\n",
      "Predicting for [SGDClassifier]\n",
      "\n",
      "Predicting for [RandomForestClassifier]\n",
      "\n",
      "Predicting for [XGBClassifier]\n",
      "\n",
      "Predicting for [LGBMClassifier]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = []\n",
    "for model in models:\n",
    "    print(f\"\\nPredicting for [{model.__class__.__name__}]\")\n",
    "    predictions.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      "----------------------------------\n",
      "[[ 8660  1494  1820]\n",
      " [  618 18343  1190]\n",
      " [ 1345  2016 16958]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.72      0.77     11974\n",
      "           0       0.84      0.91      0.87     20151\n",
      "           1       0.85      0.83      0.84     20319\n",
      "\n",
      "    accuracy                           0.84     52444\n",
      "   macro avg       0.83      0.82      0.83     52444\n",
      "weighted avg       0.84      0.84      0.84     52444\n",
      "\n",
      "LinearSVC \n",
      "----------------------------------\n",
      "[[ 8868  1324  1782]\n",
      " [  698 18071  1382]\n",
      " [ 1442  1941 16936]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.74      0.77     11974\n",
      "           0       0.85      0.90      0.87     20151\n",
      "           1       0.84      0.83      0.84     20319\n",
      "\n",
      "    accuracy                           0.84     52444\n",
      "   macro avg       0.83      0.82      0.83     52444\n",
      "weighted avg       0.84      0.84      0.84     52444\n",
      "\n",
      "SGDClassifier \n",
      "----------------------------------\n",
      "[[ 6865  2895  2214]\n",
      " [  452 18627  1072]\n",
      " [ 1053  3347 15919]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.57      0.67     11974\n",
      "           0       0.75      0.92      0.83     20151\n",
      "           1       0.83      0.78      0.81     20319\n",
      "\n",
      "    accuracy                           0.79     52444\n",
      "   macro avg       0.80      0.76      0.77     52444\n",
      "weighted avg       0.80      0.79      0.78     52444\n",
      "\n",
      "RandomForestClassifier \n",
      "----------------------------------\n",
      "[[ 8480   937  2557]\n",
      " [  525 18202  1424]\n",
      " [ 1096  1182 18041]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.71      0.77     11974\n",
      "           0       0.90      0.90      0.90     20151\n",
      "           1       0.82      0.89      0.85     20319\n",
      "\n",
      "    accuracy                           0.85     52444\n",
      "   macro avg       0.85      0.83      0.84     52444\n",
      "weighted avg       0.85      0.85      0.85     52444\n",
      "\n",
      "XGBClassifier \n",
      "----------------------------------\n",
      "[[ 7160  2693  2121]\n",
      " [  345 18660  1146]\n",
      " [ 1078  3362 15879]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.60      0.70     11974\n",
      "           0       0.76      0.93      0.83     20151\n",
      "           1       0.83      0.78      0.80     20319\n",
      "\n",
      "    accuracy                           0.80     52444\n",
      "   macro avg       0.81      0.77      0.78     52444\n",
      "weighted avg       0.80      0.80      0.79     52444\n",
      "\n",
      "LGBMClassifier \n",
      "----------------------------------\n",
      "[[ 7969  2129  1876]\n",
      " [  471 18622  1058]\n",
      " [ 1218  2594 16507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.67      0.74     11974\n",
      "           0       0.80      0.92      0.86     20151\n",
      "           1       0.85      0.81      0.83     20319\n",
      "\n",
      "    accuracy                           0.82     52444\n",
      "   macro avg       0.82      0.80      0.81     52444\n",
      "weighted avg       0.82      0.82      0.82     52444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"{model.__class__.__name__} \\n----------------------------------\")\n",
    "    print(confusion_matrix(y_test, predictions[i]))\n",
    "    print(classification_report(y_test, predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97100773, 0.96972406, 0.97372717, 0.96976292, 0.96902449])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svc, features, tweets['target'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression \n",
      "------------------------- \n",
      "score=  0.9492269631769622\n",
      "\n",
      "Linear SVC \n",
      "------------------------- \n",
      "score= 0.9706492731618044\n"
     ]
    }
   ],
   "source": [
    "# Making sure that the models are not overfitting using cross val score metric with 5 folds\n",
    "##\n",
    "print(\"Logistic Regression \\n------------------------- \\nscore= \", cross_val_score(lr, features, tweets['target'], cv=5).mean())\n",
    "print(\"\\nLinear SVC \\n------------------------- \\nscore=\", cross_val_score(svc, features, tweets['target'], cv=5).mean())\n",
    "print(\"\\nRandom Forest Classifier \\n------------------------- \\nscore=\", cross_val_score(rfc, features, tweets['target'], cv=5).mean())\n",
    "print(\"\\nXgboost Classifier \\n------------------------- \\nscore=\", cross_val_score(xgb, features, tweets['target'], cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest performed best\n",
    "# That's a good score having in mind that the model is attempting to predict between three category classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = StackingClassifier(estimators=[('rfc', rfc), ('svc', svc)], final_estimator=lr)\n",
    "stack.fit(X_train, y_train)\n",
    "pred = stack.predict(X_test)\n",
    "print(f\"{confusion_matrix(y_test, pred)}\\n{classification_report(y_test, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "# retrain\n",
    "pipe = Pipeline([('vectorizer', TfidfVectorizer()), ('classifier', LinearSVC(C=2.0, class_weight=None, dual=False, max_iter=100))])\n",
    "pipe.fit(tweets.text, tweets.target)\n",
    "pickle.dump(pipe, open('saved_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = pickle.load(open('saved_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([\"I don't know\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int(pipe.predict([\"I love people.\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
